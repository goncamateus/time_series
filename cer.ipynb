{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import skill_metrics as sm\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.dataset import CERDataset\n",
    "from src.mlp import MLPLucas\n",
    "from src.saets import AutoEncoder, FinalModule\n",
    "\n",
    "seaborn.set()\n",
    "torch.manual_seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "HORIZONS = 12\n",
    "WINDOW = 3\n",
    "FORWARD_EXPANSION = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "DECOMP_METHOD = 'fft'\n",
    "COMPLEXO_EOLICO='Amontada'\n",
    "CENTRAL_EOLICA='BC'\n",
    "TIME_STEP='1_mon'\n",
    "MES='Dec'\n",
    "DECOMP=True\n",
    "DEVICE = torch.device('cuda')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "if not os.path.exists(f'data/components/{CENTRAL_EOLICA}_{MES}_{TIME_STEP}'):\n",
    "    os.system(f'mkdir data/components/{CENTRAL_EOLICA}_{MES}_{TIME_STEP}')\n",
    "if not os.path.exists(f'data/out/{CENTRAL_EOLICA}_{MES}_{TIME_STEP}'):\n",
    "    os.system(f'mkdir data/out/{CENTRAL_EOLICA}_{MES}_{TIME_STEP}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def plot_taylor(refs: dict, predictions_dict: dict):\n",
    "\n",
    "    models = list(predictions_dict.keys())\n",
    "    colors = ['c', 'm', 'y', 'k', 'r', 'b', 'g']\n",
    "    colors = colors[:len(models)]\n",
    "    models = {model: color for model, color in zip(models, colors)}\n",
    "    for idx, (model, pred_dict) in enumerate(predictions_dict.items()):\n",
    "        taylor_stats = []\n",
    "        name = model[0]\n",
    "        if model.endswith('ND'):\n",
    "            name = name + 'ND'\n",
    "        for horizon, pred in pred_dict.items():\n",
    "            taylor_stats.append(sm.taylor_statistics(pred, refs[name][int(horizon)], 'data'))\n",
    "\n",
    "        sdev = np.array([taylor_stats[0]['sdev'][0]]+[x['sdev'][1]\n",
    "                                                    for x in taylor_stats])\n",
    "        crmsd = np.array([taylor_stats[0]['crmsd'][0]]+[x['crmsd'][1]\n",
    "                                                        for x in taylor_stats])\n",
    "        ccoef = np.array([taylor_stats[0]['ccoef'][0]]+[x['ccoef'][1]\n",
    "                                                        for x in taylor_stats])\n",
    "\n",
    "        # To change other params in the plot, check SkillMetrics documentation in\n",
    "        # https://github.com/PeterRochford/SkillMetrics/wiki/Target-Diagram-Options\n",
    "        if len(list(predictions_dict.keys())) != 1:\n",
    "            if idx != len(list(predictions_dict.keys()))-1 or len(list(predictions_dict.keys())) == 1:\n",
    "                sm.taylor_diagram(sdev, crmsd, ccoef, styleOBS='-',\n",
    "                                colOBS='g', markerobs='o',\n",
    "                                titleOBS='Observation',\n",
    "                                markercolor=models[model])\n",
    "            else:\n",
    "                sm.taylor_diagram(sdev, crmsd, ccoef, styleOBS='-',\n",
    "                                titleOBS='Observation',\n",
    "                                colOBS='g', markerobs='o', markercolor=models[model],\n",
    "                                overlay = 'on', markerLabel=models)\n",
    "        else:\n",
    "            sm.taylor_diagram(sdev, crmsd, ccoef, styleOBS='-',\n",
    "                      colOBS='g', markerobs='o',\n",
    "                      titleOBS='Observation', markercolor='c',\n",
    "                      markerLabel=['placeholder']+[\n",
    "                          k+1 for k, v in pred_dict.items()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset = CERDataset(window=WINDOW,\n",
    "                     horizons=HORIZONS,\n",
    "                     complexo_eolico=COMPLEXO_EOLICO,\n",
    "                     central_eolica=CENTRAL_EOLICA,\n",
    "                     time_step=TIME_STEP,\n",
    "                     mes=MES,\n",
    "                     decomp=DECOMP,\n",
    "                     decomp_method=DECOMP_METHOD)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128,\n",
    "                          shuffle=True, num_workers=8)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aaaaaaaaa [  4   7   9  14  19  21  26  29  33  36  41  43  46  48  52  54  57  59\n",
      "  62  64  67  70  73  78  80  82  85  87  90  94  96 100 104 107 109 113\n",
      " 119 125 127 129 134 136 138 141 144 146 149 153 156 161 163 166 169 173\n",
      " 175 179 181 184 187 190 192 194 199 202 204 206 208 210 212 216 222 224\n",
      " 227 229 232 234 236 238 241]\n",
      "Decomp serie in 6 components\n",
      "Getting test components\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/mateus/miniconda3/envs/ts/lib/python3.8/site-packages/numpy/core/_asarray.py:102: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "input_example = next(iter(train_loader))[0]\n",
    "input_size = input_example.shape[1]*input_example.shape[2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "auto_encoder = AutoEncoder(input_size=input_size,\n",
    "                               horizons=HORIZONS, device=DEVICE,\n",
    "                               forward_expansion=FORWARD_EXPANSION,\n",
    "                               num_layers=N_LAYERS,\n",
    "                               dropout=DROPOUT)\n",
    "\n",
    "trainer = Trainer(gpus=1, max_epochs=5)\n",
    "trainer.fit(auto_encoder, train_dataloader=train_loader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/mateus/miniconda3/envs/ts/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 812 K \n",
      "1 | decoder | Decoder | 1.1 M \n",
      "------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.612     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:00<00:00,  5.34it/s, loss=0.536, v_num=32, train_loss_step=0.150, train_loss_epoch=0.362] "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/mateus/miniconda3/envs/ts/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_model = FinalModule(input_size=input_size,\n",
    "                              horizons=HORIZONS, device=DEVICE,\n",
    "                              forward_expansion=FORWARD_EXPANSION,\n",
    "                              num_layers=N_LAYERS,\n",
    "                              dropout=DROPOUT)\n",
    "final_model.load_encoder(auto_encoder.encoder)\n",
    "trainer = Trainer(gpus=1, max_epochs=5)\n",
    "trainer.fit(final_model, train_dataloader=train_loader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_lucas = CERDataset(window=WINDOW,\n",
    "                           horizons=HORIZONS,\n",
    "                           complexo_eolico=COMPLEXO_EOLICO,\n",
    "                           central_eolica=CENTRAL_EOLICA,\n",
    "                           time_step=TIME_STEP,\n",
    "                           mes=MES,\n",
    "                           decomp=DECOMP,\n",
    "                           decomp_method='2fft')\n",
    "\n",
    "train_loader_lucas = DataLoader(dataset_lucas, batch_size=128,\n",
    "                                shuffle=True, num_workers=8)\n",
    "input_example_lucas = next(iter(train_loader_lucas))[0]\n",
    "input_size_lucas = input_example_lucas.shape[1] * \\\n",
    "    input_example_lucas.shape[2]\n",
    "\n",
    "mlp = MLPLucas(window_size=input_example_lucas.shape[1],\n",
    "               n_comps=input_example_lucas.shape[2],\n",
    "               horizons=HORIZONS)\n",
    "trainer = Trainer(gpus=1, max_epochs=5)\n",
    "trainer.fit(mlp, train_dataloader=train_loader_lucas)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.set_type('test')\n",
    "dataset_lucas.set_type('test')\n",
    "mlp = mlp.cpu()\n",
    "final_model = final_model.cpu()\n",
    "X_test = dataset.samples\n",
    "X_test_lucas = dataset_lucas.samples\n",
    "y = dataset.labels\n",
    "y_final = final_model(X_test).detach()/dataset.test_scaler.scale_\n",
    "y_mlp = mlp(X_test_lucas).detach()/dataset_lucas.test_scaler.scale_\n",
    "\n",
    "y_final = y_final.numpy()\n",
    "y_mlp = y_mlp.numpy()\n",
    "y = y.numpy()/dataset.test_scaler.scale_\n",
    "preds = {}\n",
    "preds['SAETS'] = {i: y_final[:, i] for i in range(HORIZONS)}\n",
    "preds['Cabral'] = {i: y_mlp[:, i] for i in range(HORIZONS)}\n",
    "refs = {key: {i: y[:, i] for i in range(HORIZONS)} for key in ['S', 'C']}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_taylor(refs, preds)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_final[:, 0])\n",
    "plt.plot(y_mlp[:, 0])\n",
    "plt.legend(['Original', 'SAETS', 'Cabral'])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('ts': conda)"
  },
  "interpreter": {
   "hash": "f83f3e32a97abb6f5eeb5a907eeed09e6f8839a9d36eb261fa7f1d4e4ea8647a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}